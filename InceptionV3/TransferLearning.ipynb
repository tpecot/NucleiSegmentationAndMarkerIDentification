{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n",
    "\n",
    "The first step is to load the libraries and functions we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import transfer_learning_parameters_interface, transfer_learning\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters\n",
    "\n",
    "The second step is to define all parameters needed for training(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_trainings = 1\n",
    "\n",
    "parameters = transfer_learning_parameters_interface(nb_trainings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning with Inception-V3\n",
    "\n",
    "Now, the training can start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_learning(nb_trainings, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {\"./logs\"} --host=127.0.0.1 --port=1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset00= \"nucleiMarkers_pixelBased_E2F3A\"\n",
    "dataset01= \"nucleiMarkers_pixelBased_E2F8\"\n",
    "dataset02= \"nucleiMarkers_pixelBased_EdU\"\n",
    "dataset03= \"nucleiMarkers_pixelBased_pH3\"\n",
    "\n",
    "direc_save = \"./trainedClassifiers/markerIdentification/\"\n",
    "direc_data = \"./trainingDataNpz/markerIdentification/Confocal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "imaging_field_x = 65\n",
    "imaging_field_y = 65\n",
    "nb_channels = 1\n",
    "batch_size = 512\n",
    "nb_epochs = 10\n",
    "\n",
    "# optimizer\n",
    "optimizer = SGD(lr = 0.01, decay = 1e-7, momentum = 0.9, nesterov = True)\n",
    "lr_sched = rate_scheduler(lr = 0.01, decay = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E2F3A\n",
    "nb_classes = 3\n",
    "trained_classifier_directory = \"./trainedClassifiers/nucleiSegmentation/\"\n",
    "model_prefix = \"nuclei_CFWF_IncV3_InceptionV3\"\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# remove last layer and replace with a layer corresponding to the actual number of classes\n",
    "nb_actual_classes = 2\n",
    "model.layers.pop()\n",
    "lastLayer = Dense(nb_actual_classes, activation='softmax', name='predictions')(model.layers[-1].output)\n",
    "newModel = Model(model.layers[0].output,lastLayer)\n",
    "del model\n",
    "\n",
    "# just train the last layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset00, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset00, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del newModel\n",
    "\n",
    "\n",
    "# E2F8\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# remove last layer and replace with a layer corresponding to the actual number of classes\n",
    "model.layers.pop()\n",
    "lastLayer = Dense(nb_actual_classes, activation='softmax', name='predictions')(model.layers[-1].output)\n",
    "newModel = Model(model.layers[0].output,lastLayer)\n",
    "del model\n",
    "\n",
    "# just train the last layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset01, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset01, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del newModel\n",
    "\n",
    "# EdU\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# just train the last layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset02, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset02, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del model\n",
    "\n",
    "# pH3\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# just train the last layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset03, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_CF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset03, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset10= \"nucleiMarkers_pixelBased_E2F3A\"\n",
    "dataset11= \"nucleiMarkers_pixelBased_E2F8\"\n",
    "dataset12= \"nucleiMarkers_pixelBased_E2F4\"\n",
    "dataset13= \"nucleiMarkers_pixelBased_EdU\"\n",
    "dataset14= \"nucleiMarkers_pixelBased_pH3\"\n",
    "\n",
    "direc_save = \"./trainedClassifiers/markerIdentification/\"\n",
    "direc_data = \"./trainingDataNpz/markerIdentification/Widefield/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E2F3A\n",
    "nb_classes = 3\n",
    "trained_classifier_directory = \"./trainedClassifiers/nucleiSegmentation/\"\n",
    "model_prefix = \"nuclei_CFWF_IncV3_InceptionV3\"\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# remove last layer and replace with a layer corresponding to the actual number of classes\n",
    "nb_actual_classes = 2\n",
    "model.layers.pop()\n",
    "lastLayer = Dense(nb_actual_classes, activation='softmax', name='predictions')(model.layers[-1].output)\n",
    "newModel = Model(model.layers[0].output,lastLayer)\n",
    "del model\n",
    "\n",
    "# just train the last layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset10, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset10, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del newModel\n",
    "\n",
    "\n",
    "# E2F8\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# remove last layer and replace with a layer corresponding to the actual number of classes\n",
    "model.layers.pop()\n",
    "lastLayer = Dense(nb_actual_classes, activation='softmax', name='predictions')(model.layers[-1].output)\n",
    "newModel = Model(model.layers[0].output,lastLayer)\n",
    "del model\n",
    "\n",
    "# just train the last layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset11, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset11, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del newModel\n",
    "\n",
    "# E2F4\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# remove last layer and replace with a layer corresponding to the actual number of classes\n",
    "model.layers.pop()\n",
    "lastLayer = Dense(nb_actual_classes, activation='softmax', name='predictions')(model.layers[-1].output)\n",
    "newModel = Model(model.layers[0].output,lastLayer)\n",
    "del model\n",
    "\n",
    "# just train the last layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset12, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in newModel.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = newModel, dataset = dataset12, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del newModel\n",
    "\n",
    "# EdU\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# just train the last layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset13, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset13, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del model\n",
    "\n",
    "# pH3\n",
    "model_weights = os.path.join(trained_classifier_directory,  model_prefix + \".h5\")\n",
    "model = inceptionV3(n_channels = nb_channels, n_features = nb_classes, dimx = imaging_field_x, dimy = imaging_field_y, weights_path = model_weights)\n",
    "\n",
    "# just train the last layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nb_epochs = 1\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset14, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched1, nb_augmentations = nb_augmentations)\n",
    "\n",
    "# unfreeze all layers layer\n",
    "for layer in model.layers[:307]:\n",
    "    layer.trainable = True\n",
    "\n",
    "nb_epochs = 5\n",
    "\n",
    "expt = \"InceptionV3_WF_TL\"\n",
    "train_model_sample(model = model, dataset = dataset14, optimizer = optimizer, \n",
    "                   expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   direc_save = direc_save, direc_data = direc_data, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations)\n",
    "\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
