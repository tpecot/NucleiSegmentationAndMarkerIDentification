{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training U-Net\n",
    "\n",
    "The first step is to load the modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from utils import rate_scheduler, train_model_sample\n",
    "from models import unet as unet\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the training and validation datasets we want to use to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training_CF = \"datasets/nucleiSegmentation_E2Fs/training_CF\"\n",
    "dataset_validation_CF = \"datasets/nucleiSegmentation_E2Fs/validation_CF\"\n",
    "\n",
    "dataset_training_WF = \"datasets/nucleiSegmentation_E2Fs/training_WF\"\n",
    "dataset_validation_WF = \"datasets/nucleiSegmentation_E2Fs/validation_WF\"\n",
    "\n",
    "dataset_training_CFWF = \"datasets/nucleiSegmentation_E2Fs/training_CFWF\"\n",
    "dataset_validation_CFWF = \"datasets/nucleiSegmentation_E2Fs/validation_CFWF\"\n",
    "\n",
    "direc_save = \"./trainedClassifiers/nucleiSegmentation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the global parameters used for training the classifier: <br>\n",
    "    1) the image dimensions (imaging_field_x and imaging_field_y) <br>\n",
    "    2) the number of classes <br>\n",
    "    3) the number of images trained at once (batch_size) <br>\n",
    "    4) the number of epochs <br>\n",
    "    5) the number of data augmentations <br>\n",
    "    6) the class to dilate, if any <br> \n",
    "    7) the dilation radius for the class to dilate, if any <br> <br>\n",
    "We also set up the optimizer that will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "imaging_field_x = 256\n",
    "imaging_field_y = 256\n",
    "nb_classes = 3\n",
    "batch_size = 1\n",
    "nb_epochs = 10\n",
    "nb_augmentations = 100\n",
    "class_to_dilate = [1,0,0]\n",
    "dilation_radius = 1\n",
    "\n",
    "# optimizer\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "lr_sched = rate_scheduler(lr = 1e-4, decay = 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0528 17:26:00.519341 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0528 17:26:00.521277 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0528 17:26:00.525899 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0528 17:26:00.567018 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0528 17:26:00.568621 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0528 17:26:01.907721 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0528 17:26:02.126715 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0528 17:26:02.869253 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0528 17:26:12.143046 140700929681216 deprecation_wrapper.py:119] From /home/thierry/.local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 training images\n",
      "3 validation images\n",
      "Epoch 1/10\n",
      "  8/900 [..............................] - ETA: 39:25 - loss: 1.2224 - acc: 0.5256"
     ]
    }
   ],
   "source": [
    "# Confocal\n",
    "model = unet(nb_classes, imaging_field_x, imaging_field_y)\n",
    "expt = \"Unet_CFtraining_DA100_10ep\"\n",
    "train_model_sample(model = model, \n",
    "                   dataset_training = dataset_training_CF, dataset_validation = dataset_validation_CF, \n",
    "                   optimizer = optimizer, expt = expt, batch_size = batch_size, n_epoch = nb_epochs, \n",
    "                   imaging_field_x = imaging_field_x, imaging_field_y = imaging_field_y,\n",
    "                   direc_save = direc_save, lr_sched = lr_sched, nb_augmentations = nb_augmentations,\n",
    "                   class_to_dilate = class_to_dilate, dil_radius = dilation_radius)\n",
    "\n",
    "del model\n",
    "\n",
    "# Wide-field\n",
    "model = unet(nb_classes, imaging_field_x, imaging_field_y)\n",
    "\n",
    "expt = \"Unet_WFtraining_DA100_10ep\"\n",
    "train_model_sample(model = model, \n",
    "                   dataset_training = dataset_training_WF, dataset_validation = dataset_validation_WF, \n",
    "                   optimizer = optimizer, expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   imaging_field_x = imaging_field_x, imaging_field_y = imaging_field_y, direc_save = direc_save, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations,\n",
    "                   class_to_dilate = class_to_dilate, dil_radius = dilation_radius)\n",
    "\n",
    "del model\n",
    "\n",
    "# Confocal & Wide-field\n",
    "model = unet(nb_classes, imaging_field_x, imaging_field_y)\n",
    "\n",
    "expt = \"Unet_CFWFtraining_DA100_10ep\"\n",
    "train_model_sample(model = model, \n",
    "                   dataset_training = dataset_training_CFWF, dataset_validation = dataset_validation_CFWF, \n",
    "                   optimizer = optimizer, expt = expt, batch_size = batch_size, n_epoch = nb_epochs,\n",
    "                   imaging_field_x = imaging_field_x, imaging_field_y = imaging_field_y, direc_save = direc_save, \n",
    "                   lr_sched = lr_sched, nb_augmentations = nb_augmentations,\n",
    "                   class_to_dilate = class_to_dilate, dil_radius = dilation_radius)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
